{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models.MLP import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "layers = 3\n",
    "output_dim = 1\n",
    "learning_rate = 0.00005\n",
    "num_epochs = 4000\n",
    "epochs_step = 10\n",
    "batch_size = 32\n",
    "test_size=0.3\n",
    "dropout_rate = 0.5\n",
    "pos_weight_ratio = 10\n",
    "# ds_name = 'datasets/20220328-or-eng-shrink-full.csv'\n",
    "ds_name = 'pre_processing/output2.csv'\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1202, 27)\n",
      "(1202,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(ds_name)\n",
    "\n",
    "# removed_cols = ['Postoperative Olanzapine', 'Postoperative Fluphenazine', 'Postoperative Flupentixol']\n",
    "# data = data.drop(removed_cols, axis=1)\n",
    "\n",
    "# 将特征和目标分开\n",
    "features = data.drop('Label', axis=1).values\n",
    "target = data['Label'].values\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features, target, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为PyTorch张量\n",
    "train_features = torch.Tensor(train_features)\n",
    "test_features = torch.Tensor(test_features)\n",
    "train_target = torch.tensor(train_target, dtype=torch.float32).view(-1, 1)\n",
    "test_target = torch.tensor(test_target, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(train_features, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "input_dim = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1782/2821676749.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_weight = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.1136)\n"
     ]
    }
   ],
   "source": [
    "# Random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = MLP(input_dim, hidden_dim, output_dim,\n",
    "            layers=layers, dropout_rate=dropout_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pos_weight = torch.tensor(\n",
    "    (train_target == 0).sum() / (train_target == 1).sum(), dtype=torch.float32)\n",
    "print(pos_weight)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight*pos_weight_ratio)\n",
    "unratio_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# To device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "unratio_criterion = unratio_criterion.to(device)\n",
    "\n",
    "train_features = train_features.to(device)\n",
    "test_features = test_features.to(device)\n",
    "train_target = train_target.to(device)\n",
    "test_target = test_target.to(device)\n",
    "\n",
    "# Compile model\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=100):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    sensitivities = []\n",
    "    sppecificities = []\n",
    "    best_model = None\n",
    "    best_test_loss = 1000\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "\n",
    "        if epoch == num_epochs // 2:\n",
    "            criterion = nn.BCEWithLogitsLoss(\n",
    "                pos_weight=pos_weight*pos_weight_ratio)\n",
    "            criterion = criterion.to(device)\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # To device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # save model\n",
    "        if (epoch + 1) % epochs_step == 0:\n",
    "            # test\n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            model.eval()\n",
    "            outputs = model(test_features)\n",
    "            test_loss = unratio_criterion(outputs, test_target)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "            outputs = outputs > 0.5\n",
    "\n",
    "            sensitivity = torch.sum(outputs[test_target == 1] == 1).item(\n",
    "            ) / torch.sum(test_target == 1).item()\n",
    "            sensitivities.append(sensitivity)\n",
    "\n",
    "            sppecificity = torch.sum(outputs[test_target == 0] == 0).item(\n",
    "            ) / torch.sum(test_target == 0).item()\n",
    "            sppecificities.append(sppecificity)\n",
    "\n",
    "            if test_loss < best_test_loss:\n",
    "                best_test_loss = test_loss\n",
    "                best_model = model\n",
    "\n",
    "            # torch.save(model.state_dict(),\n",
    "            #            'pths/MLP-epoch-{}-acc-{:.4f}-sens-{:.4f}.pth'.format(epoch+1, acc*100, sensitivity*100))\n",
    "    \n",
    "            if (epoch + 1) % (epochs_step*10)== 0:\n",
    "                print('Epoch [{}/{}], Loss: {:.4f}, Test Loss: {:.4f}, Sensitivity: {:.4f}, Specificity: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, train_loss, test_loss.item(), sensitivity, sppecificity))\n",
    "    \n",
    "    return train_losses, test_losses, sensitivities, sppecificities, best_model, best_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples: 44\n",
      "Number of negative samples: 797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 103/4000 [00:43<02:46, 23.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 6.0187, Test Loss: 1.4523, Sensitivity: 0.0000, Specificity: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 205/4000 [00:47<02:30, 25.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/4000], Loss: 4.0477, Test Loss: 1.8201, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 304/4000 [00:51<02:38, 23.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/4000], Loss: 3.2418, Test Loss: 2.0141, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 404/4000 [00:56<02:24, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/4000], Loss: 3.4366, Test Loss: 1.9991, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 503/4000 [01:00<02:23, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/4000], Loss: 3.5199, Test Loss: 1.9622, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 605/4000 [01:04<02:16, 24.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [600/4000], Loss: 3.2193, Test Loss: 1.9411, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 704/4000 [01:09<02:28, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [700/4000], Loss: 3.1682, Test Loss: 1.9276, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 802/4000 [01:13<02:39, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [800/4000], Loss: 2.9818, Test Loss: 1.9243, Sensitivity: 1.0000, Specificity: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 904/4000 [01:18<01:56, 26.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [900/4000], Loss: 2.9943, Test Loss: 1.9070, Sensitivity: 1.0000, Specificity: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1003/4000 [01:21<02:01, 24.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/4000], Loss: 2.9910, Test Loss: 1.8604, Sensitivity: 1.0000, Specificity: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1102/4000 [01:26<01:55, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1100/4000], Loss: 3.0338, Test Loss: 1.8574, Sensitivity: 1.0000, Specificity: 0.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1204/4000 [01:30<02:06, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1200/4000], Loss: 2.6813, Test Loss: 1.8099, Sensitivity: 1.0000, Specificity: 0.2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1304/4000 [01:36<02:17, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1300/4000], Loss: 2.7832, Test Loss: 1.7691, Sensitivity: 1.0000, Specificity: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1403/4000 [01:40<01:50, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1400/4000], Loss: 2.5725, Test Loss: 1.7306, Sensitivity: 1.0000, Specificity: 0.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1502/4000 [01:45<02:13, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1500/4000], Loss: 2.6665, Test Loss: 1.6793, Sensitivity: 1.0000, Specificity: 0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1603/4000 [01:49<01:31, 26.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1600/4000], Loss: 2.7312, Test Loss: 1.6138, Sensitivity: 0.9583, Specificity: 0.4273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1705/4000 [01:54<01:37, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1700/4000], Loss: 2.5684, Test Loss: 1.5706, Sensitivity: 0.9583, Specificity: 0.4481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1804/4000 [01:58<01:43, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1800/4000], Loss: 2.3266, Test Loss: 1.5353, Sensitivity: 0.9583, Specificity: 0.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1903/4000 [02:02<01:33, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1900/4000], Loss: 2.2589, Test Loss: 1.4945, Sensitivity: 0.9167, Specificity: 0.4955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2002/4000 [02:07<01:35, 20.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/4000], Loss: 2.4411, Test Loss: 1.4541, Sensitivity: 0.9167, Specificity: 0.5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2102/4000 [02:12<01:21, 23.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2100/4000], Loss: 2.3952, Test Loss: 1.4493, Sensitivity: 0.9167, Specificity: 0.5341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2204/4000 [02:16<01:15, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2200/4000], Loss: 2.1008, Test Loss: 1.4499, Sensitivity: 0.8333, Specificity: 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2303/4000 [02:21<01:09, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2300/4000], Loss: 2.1069, Test Loss: 1.4667, Sensitivity: 0.7917, Specificity: 0.5816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2405/4000 [02:25<01:04, 24.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2400/4000], Loss: 2.0903, Test Loss: 1.4874, Sensitivity: 0.7500, Specificity: 0.5994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2504/4000 [02:29<00:57, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2500/4000], Loss: 2.4286, Test Loss: 1.5230, Sensitivity: 0.7500, Specificity: 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 2603/4000 [02:33<00:57, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2600/4000], Loss: 2.0914, Test Loss: 1.5546, Sensitivity: 0.7500, Specificity: 0.6142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2702/4000 [02:38<01:10, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2700/4000], Loss: 2.0710, Test Loss: 1.6147, Sensitivity: 0.7500, Specificity: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2802/4000 [02:42<01:09, 17.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2800/4000], Loss: 2.0648, Test Loss: 1.6663, Sensitivity: 0.7083, Specificity: 0.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2904/4000 [02:47<00:42, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2900/4000], Loss: 1.7805, Test Loss: 1.7370, Sensitivity: 0.7083, Specificity: 0.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3004/4000 [02:51<00:45, 21.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3000/4000], Loss: 1.9471, Test Loss: 1.8357, Sensitivity: 0.7083, Specificity: 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3103/4000 [02:56<00:41, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3100/4000], Loss: 1.8215, Test Loss: 1.9104, Sensitivity: 0.7083, Specificity: 0.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 3204/4000 [03:02<00:40, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3200/4000], Loss: 1.6971, Test Loss: 2.0013, Sensitivity: 0.7083, Specificity: 0.6914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 3303/4000 [03:06<00:31, 21.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3300/4000], Loss: 1.7396, Test Loss: 2.1750, Sensitivity: 0.6667, Specificity: 0.7122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 3402/4000 [03:11<00:25, 23.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3400/4000], Loss: 1.7166, Test Loss: 2.3362, Sensitivity: 0.6667, Specificity: 0.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 3503/4000 [03:15<00:23, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3500/4000], Loss: 1.6381, Test Loss: 2.5283, Sensitivity: 0.6667, Specificity: 0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3602/4000 [03:20<00:18, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3600/4000], Loss: 1.7542, Test Loss: 2.6637, Sensitivity: 0.6250, Specificity: 0.7359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3608/4000 [03:20<00:18, 21.04it/s]"
     ]
    }
   ],
   "source": [
    "if train == True:\n",
    "    # torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "    # Count number of positive and negative samples\n",
    "    print('Number of positive samples: {}'.format((train_target == 1).sum()))\n",
    "    print('Number of negative samples: {}'.format((train_target == 0).sum()))\n",
    "\n",
    "    train_losses, test_losses, sensitivities, sppecificities, model, best_test_loss = train_model(\n",
    "        model, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "    # Plot losses and accuracies separately\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(30, 5))\n",
    "    ax[0].plot(train_losses)\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Train loss')\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[1].plot(test_losses)\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Test loss')\n",
    "    ax[2].plot(sensitivities)\n",
    "    ax[2].set_xlabel('Epochs')\n",
    "    ax[2].set_ylabel('Test sensitivity')\n",
    "    ax[3].plot(sppecificities)\n",
    "    ax[3].set_xlabel('Epochs')\n",
    "    ax[3].set_ylabel('Test specificity')\n",
    "    \n",
    "    plt.savefig('outputs/MLP-{:04}-{:02.4f}.png'.format(num_epochs, test_losses[-1]*100))\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model.state_dict(), 'pths/MLP-epoch-{}-acc-{:.4f}.pth'.format(num_epochs, best_test_loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, features, target):\n",
    "    # Test in all data\n",
    "    model.eval()\n",
    "    outputs = model(features)\n",
    "    outputs = outputs > 0.5\n",
    "\n",
    "    # Reshape\n",
    "    outputs = outputs.view(-1)\n",
    "    target = target.view(-1)\n",
    "    success = torch.sum(outputs == target).item()\n",
    "    print('Success: {}/{}'.format(success, len(target)))\n",
    "\n",
    "    acc = success / len(target)\n",
    "    print('Accuracy: {:.2f}'.format(acc))\n",
    "\n",
    "    # Confusion matrix\n",
    "    TP = torch.sum((outputs == 1) & (target == 1)).item()\n",
    "    TN = torch.sum((outputs == 0) & (target == 0)).item()\n",
    "    FP = torch.sum((outputs == 1) & (target == 0)).item()\n",
    "    FN = torch.sum((outputs == 0) & (target == 1)).item()\n",
    "\n",
    "    print('TP: {}, TN: {}, FP: {}, FN: {}'.format(TP, TN, FP, FN))\n",
    "\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    print('Sensitivity: {:.2f}, Specificity: {:.2f}'.format(sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In test set:\n",
      "Success: 219/361\n",
      "Accuracy: 0.61\n",
      "TP: 17, TN: 202, FP: 135, FN: 7\n",
      "Sensitivity: 0.71, Specificity: 0.60\n",
      "\n",
      "In all data:\n",
      "Success: 738/1202\n",
      "Accuracy: 0.61\n",
      "TP: 61, TN: 677, FP: 457, FN: 7\n",
      "Sensitivity: 0.90, Specificity: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# model.load_state_dict(torch.load('pths/MLP-500-9.5580e-01.pth'))\n",
    "\n",
    "print('In test set:')\n",
    "test_model(model, test_features, test_target)\n",
    "\n",
    "print('\\nIn all data:')\n",
    "test_model(model, torch.Tensor(features).to(device), torch.Tensor(target).to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
